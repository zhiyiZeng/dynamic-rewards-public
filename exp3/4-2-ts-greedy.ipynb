{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy方法选择最优arm\n",
    "(只是选，还没有concat，concat要到concat-reward.ipynb那)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from DataLoader.DataLoader import DataLoader\n",
    "from DataLoader.DataBasedAgent import DataBasedAgent\n",
    "from DataLoader.DataRLAgent import DataRLAgent\n",
    "import DeepRLAgent.VanillaInput.Train as Train\n",
    "from PatternDetectionInCandleStick.Evaluation import Evaluation\n",
    "import distinctipy\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "Train = reload(Train)\n",
    "DeepRL = Train.Train\n",
    "from utils_best_arm import add_train_portfo, add_test_portfo, plot_return, calc_return, plot_action_point, setup_logger\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "device = \"cpu\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CURRENT_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    DATASET_NAME, \n",
    "    begin_date='2010-01-01', \n",
    "    end_date='2020-08-24', \n",
    "    split_point='2018-08-24', \n",
    "    initial_investment=1000,\n",
    "    transaction_cost=0.0001,\n",
    "    load_from_file=True,\n",
    "    reward_type=\"profit\",\n",
    "    seed=42, \n",
    "    state_mode=1,\n",
    "    n_episodes=5,\n",
    "    lamb=0.0001,\n",
    "    GAMMA=0.7, \n",
    "    n_step=5, \n",
    "    BATCH_SIZE=10, \n",
    "    ReplayMemorySize=20,\n",
    "    TARGET_UPDATE=5,\n",
    "    window_size=None, \n",
    "    train_portfolios={},\n",
    "    test_portfolios={},\n",
    "    arms=[],\n",
    "    show_all = False,\n",
    "    ratio_threshold=0.9,\n",
    "):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    data_loader = DataLoader(DATASET_NAME, begin_date=begin_date, end_date=end_date, split_point=split_point, load_from_file=load_from_file)\n",
    "    dataTrain_agent = DataRLAgent(data_loader.data_train, state_mode, 'action_encoder_decoder', device, GAMMA, n_step, BATCH_SIZE, window_size, transaction_cost)\n",
    "    dataTest_agent = DataRLAgent(data_loader.data_test, state_mode, 'action_encoder_decoder', device, GAMMA, n_step, BATCH_SIZE, window_size, transaction_cost)\n",
    "\n",
    "    agent = DeepRL(data_loader, dataTrain_agent, dataTest_agent, \n",
    "                DATASET_NAME,  state_mode, window_size, transaction_cost,\n",
    "                BATCH_SIZE=BATCH_SIZE, GAMMA=GAMMA, ReplayMemorySize=ReplayMemorySize,\n",
    "                TARGET_UPDATE=TARGET_UPDATE, n_step=n_step, arms=arms)\n",
    "    \n",
    "    arm = arms[0]\n",
    "    agent_test = agent.test(initial_investment=initial_investment, test_type='test', arm=arm, model_path=arm[\"model_path\"])\n",
    "\n",
    "    _test_portfolio = agent_test.get_daily_portfolio_value()\n",
    "    test_portfolio = pd.Series(_test_portfolio).pct_change(1).fillna(0).values.tolist() \n",
    "    mean = np.mean(test_portfolio)\n",
    "    std = np.std(test_portfolio)\n",
    "    if std != 0:\n",
    "        sharpe = mean / std\n",
    "    else:\n",
    "        sharpe = mean\n",
    "    cumreturn = _test_portfolio[-1] / _test_portfolio[0] - 1\n",
    "    arm[\"sharpe_list\"].append(sharpe)\n",
    "    arm[\"cumreturn_list\"].append(cumreturn)\n",
    "    return data_loader, arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(begin_date, split_date, kwargs, threshold1, threshold2, _file, seed, arms,):\n",
    "    _split_point = '20{}-{}-01' \n",
    "    split_year = int(split_date.split(\"-\")[0][-2:])\n",
    "    for year in range(1):\n",
    "        for month in range(1, 13):\n",
    "            if month < 10:\n",
    "                month = f\"0{month}\"\n",
    "            for day in range(1, 30, 6):\n",
    "                _split_point = datetime.strptime(f\"20{split_year + year}-{month}-{day}\", \"%Y-%m-%d\")\n",
    "                end_date = _split_point + timedelta(days=180)\n",
    "                split_point = str(_split_point.date())\n",
    "                end_date = str(end_date.date())\n",
    "\n",
    "                for arm in arms:\n",
    "                    # NOTE: ts\n",
    "                    # theta_hat = np.random.beta(arm[\"a\"], arm[\"b\"])\n",
    "                    # NOTE: greedy\n",
    "                    theta_hat = arm[\"a\"] / (arm[\"a\"] + arm[\"b\"])\n",
    "                    arm[\"theta\"] = theta_hat\n",
    "\n",
    "                max_index = int(sorted(arms, key=lambda x: x[\"theta\"], reverse=True)[0][\"index\"])\n",
    "                for arm in arms:\n",
    "                    if arm[\"used\"] < threshold1:\n",
    "                        max_index = arm[\"index\"]\n",
    "                        break\n",
    "                arm = arms[max_index]\n",
    "\n",
    "                kwargs.update({\n",
    "                    \"begin_date\": begin_date, \n",
    "                    \"end_date\": end_date, \n",
    "                    \"split_point\": split_point, \n",
    "                    \"DATASET_NAME\": _file,\n",
    "                    \"reward_type\": \"\",\n",
    "                    \"seed\": seed,\n",
    "                    \"n_episodes\": 140,\n",
    "                    \"arms\": [arm],\n",
    "                    \"show_all\": True,\n",
    "                    \"ratio_threshold\": 5,\n",
    "                    \"train_portfolios\": {},\n",
    "                    \"test_portfolios\": {},\n",
    "                })\n",
    "\n",
    "                data_loader, arm = train(**kwargs)\n",
    "                \n",
    "                _count = 0\n",
    "                for _arm in arms:\n",
    "                    if _arm[\"sharpe_list\"].__len__() == 0: continue\n",
    "                    if arm[\"sharpe_list\"][-1] > np.mean(_arm[\"sharpe_list\"]) and arm[\"cumreturn_list\"][-1] > np.mean(_arm[\"cumreturn_list\"]):\n",
    "                        _count += 1\n",
    "                    \n",
    "                arm[\"used\"] += 1\n",
    "                \n",
    "                if arm[\"used\"] >= threshold1:\n",
    "                    if _count >= threshold2:\n",
    "                        arm[\"a\"] += 1\n",
    "                    else:\n",
    "                        arm[\"b\"] += 1\n",
    "                else:\n",
    "                    arm[\"a\"] += 1\n",
    "\n",
    "                # print(f\"tmp: {arm['name']}-{arm['lamb']}\", arm[\"a\"], arm[\"b\"])\n",
    "\n",
    "    for arm in arms:\n",
    "        if arm[\"sharpe_list\"].__len__() == 0 or np.mean(arm[\"sharpe_list\"]) == 0 or arm[\"a\"] <= threshold1:\n",
    "            arm[\"theta\"] = 0\n",
    "        else:\n",
    "            arm[\"theta\"] = arm[\"a\"] / (arm[\"a\"] + arm[\"b\"])\n",
    "\n",
    "    arms = sorted(arms, key=lambda x: x[\"theta\"], reverse=True)\n",
    "    arm = arms[0]\n",
    "    return arm, end_date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_investment = 1000\n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    \"load_from_file\": True, \n",
    "    \"transaction_cost\": 0.0000,\n",
    "    \"initial_investment\": initial_investment,\n",
    "    \"state_mode\": 1,\n",
    "    \"GAMMA\": 0.7, \n",
    "    \"n_step\": 5, \n",
    "    \"BATCH_SIZE\": 10, \n",
    "    \"ReplayMemorySize\": 20,\n",
    "    \"TARGET_UPDATE\": 5,\n",
    "    \"window_size\": None, \n",
    "    \"lamb\": 0.0,\n",
    "}\n",
    "\n",
    "_file = \"AAPL\"\n",
    "\n",
    "_begin_date = '20{}-01-01'\n",
    "_end_date = '20{}-01-01'\n",
    "_split_point = '20{}-01-01' \n",
    "\n",
    "def add_arm(arms, model_path, name, lamb):\n",
    "    arm = { \"index\": len(arms), \"name\": name, \"theta\": 0, \"a\": 1, \"b\": 1, \"sharpe_list\": [], \"cumreturn_list\": [], \"lamb\": lamb, \"used\": 0}\n",
    "    arm[\"model_path\"] = os.path.join(model_path, f'model_{arm[\"name\"]}_{arm[\"lamb\"]}_{seed}.pkl')\n",
    "    arms.append(arm)\n",
    "\n",
    "\n",
    "random_seeds = 100\n",
    "threshold1, threshold2 = 2, 3\n",
    "results = {}\n",
    "tmp_dt = {}\n",
    "files = sorted(os.listdir(\"./Data/\"))\n",
    "for _file in files[19:]:\n",
    "    results2 = {}\n",
    "    for seed in tqdm(range(random_seeds)):\n",
    "        ls = []\n",
    "        bhs = []\n",
    "    \n",
    "        train_portfolios = {}\n",
    "        test_portfolios = {}\n",
    "        \n",
    "        for year in range(3):\n",
    "            model_begin_date = _begin_date.format(16+year)\n",
    "            model_end_date = _end_date.format(19+year)\n",
    "            split_point = _split_point.format(18+year)\n",
    "\n",
    "            arms = []\n",
    "            model_path = f\"Results/{_file}/{model_begin_date}~{model_end_date}/{seed}/train\"\n",
    "            add_arm(arms, model_path, \"profit\", 0)\n",
    "            # add_arm(arms, model_path, \"sharpe\", 0.01)\n",
    "            # add_arm(arms, model_path, \"volatility\", 10)\n",
    "            add_arm(arms, model_path, \"regularized\", 0.01)\n",
    "            add_arm(arms, model_path, \"regularized\", 0.05)\n",
    "            add_arm(arms, model_path, \"regularized\", 0.1)\n",
    "            # add_arm(arms, model_path, \"regularized\", 0.2)\n",
    "            \n",
    "            arm, end_date = valid(model_begin_date, split_point, kwargs, threshold1, threshold2, _file, seed, arms)\n",
    "            test_start_date = end_date\n",
    "            test_start_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n",
    "            test_end_date = test_start_date + timedelta(days=365)\n",
    "            test_end_date = str(test_end_date.date())\n",
    "            if not results2.get((str(test_start_date.date()), test_end_date)):\n",
    "                results2[(str(test_start_date.date()), test_end_date)] = []\n",
    "            results2[(str(test_start_date.date()), test_end_date)].append(f\"{arm['name']}-{arm['lamb']}\")\n",
    "\n",
    "            # print(test_start_date.date(), test_end_date, f\"{arm['name']}-{arm['lamb']}\")\n",
    "    results[_file] = results2\n",
    "\n",
    "    for key, value in results.items():\n",
    "        a = dict((':'.join(k), v) for k,v in value.items())\n",
    "        tmp_dt[key] = a\n",
    "\n",
    "    with open(f\"./ts-run-results/[{random_seeds}]ts-greedy2.json\", \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(json.dumps(tmp_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# dt = {}\n",
    "# for key, value in results.items():\n",
    "#     a = dict((':'.join(k), v) for k,v in value.items())\n",
    "#     dt[key] = a\n",
    "\n",
    "# with open(f\"./ts-run-results/[{random_seeds}]ts-greedy.json\", \"r\", encoding=\"utf8\") as f:\n",
    "#     dt2 = json.loads(f.read())\n",
    "\n",
    "# dt2.update(dt)\n",
    "\n",
    "\n",
    "# with open(f\"./ts-run-results/[{random_seeds}]ts-greedy2.json\", \"w\", encoding=\"utf8\") as f:\n",
    "#     f.write(json.dumps(dt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70b8d5fa9004939b645b5ed04b7a6b5965238ce0024678cbb559f81b063cafc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
