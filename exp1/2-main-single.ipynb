{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from DataLoader.DataLoader import DataLoader\n",
    "from DataLoader.DataBasedAgent import DataBasedAgent\n",
    "from DataLoader.DataRLAgent import DataRLAgent\n",
    "import DeepRLAgent.VanillaInput.Train as Train\n",
    "from PatternDetectionInCandleStick.Evaluation import Evaluation\n",
    "import distinctipy\n",
    "\n",
    "import utils\n",
    "from importlib import reload\n",
    "import re\n",
    "from utils import setup_logger\n",
    "\n",
    "Train = reload(Train)\n",
    "DeepRL = Train.Train\n",
    "utils = reload(utils)\n",
    "from utils import add_train_portfo, add_test_portfo, plot_return, calc_return, plot_action_point, calc_bh\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "device = \"cpu\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CURRENT_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    DATASET_NAME, \n",
    "    split_point='2018-01-01', \n",
    "    begin_date='2010-01-01', \n",
    "    end_date='2020-08-24', \n",
    "    initial_investment=1000,\n",
    "    transaction_cost=0.0001,\n",
    "    load_from_file=True,\n",
    "    reward_type=\"profit\",\n",
    "    seed=42, \n",
    "    state_mode=1,\n",
    "    n_episodes=5,\n",
    "    lamb=0.0001,\n",
    "    GAMMA=0.7, \n",
    "    n_step=5, \n",
    "    BATCH_SIZE=10, \n",
    "    ReplayMemorySize=20,\n",
    "    TARGET_UPDATE=5,\n",
    "    window_size=None, \n",
    "    train_portfolios={},\n",
    "    test_portfolios={},\n",
    "    arms={},\n",
    "    show_all = False,\n",
    "    ratio_threshold=0.9,\n",
    "):\n",
    "    data_loader = DataLoader(DATASET_NAME, split_point=split_point, begin_date=begin_date, end_date=end_date, load_from_file=load_from_file)\n",
    "    \n",
    "    dataTrain_agent = DataRLAgent(data_loader.data_train, state_mode, 'action_encoder_decoder', device, GAMMA, n_step, BATCH_SIZE, window_size, transaction_cost)\n",
    "    dataTest_agent = DataRLAgent(data_loader.data_test, state_mode, 'action_encoder_decoder', device, GAMMA, n_step, BATCH_SIZE, window_size, transaction_cost)\n",
    "    # NOTE 这俩是b&h\n",
    "    # dataTrain_base = DataBasedAgent(data_loader.data_train, data_loader.patterns, 'action_deepRL', device, GAMMA, n_step, BATCH_SIZE, transaction_cost)\n",
    "    # dataTest_base = DataBasedAgent(data_loader.data_test, data_loader.patterns, 'action_deepRL', device, GAMMA, n_step, BATCH_SIZE, transaction_cost)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    agent = DeepRL(data_loader, dataTrain_agent, dataTest_agent, \n",
    "                DATASET_NAME,  state_mode, window_size, transaction_cost,\n",
    "                BATCH_SIZE=BATCH_SIZE, GAMMA=GAMMA, ReplayMemorySize=ReplayMemorySize,\n",
    "                TARGET_UPDATE=TARGET_UPDATE, n_step=n_step, arms=arms)\n",
    "\n",
    "    agent.train(arms, n_episodes, ratio_threshold, seed, begin_date, end_date)\n",
    "\n",
    "    agent_eval = agent.test(initial_investment=initial_investment, test_type='train', model_path=\"\")\n",
    "    train_portfolio = agent_eval.get_daily_portfolio_value()\n",
    "    \n",
    "    agent_test = agent.test(initial_investment=initial_investment, test_type='test', model_path=\"\")\n",
    "    test_portfolio = agent_test.get_daily_portfolio_value()\n",
    "\n",
    "    # 选出最优的arm    \n",
    "    max_index = int(sorted(arms, key=lambda x: x[\"theta\"], reverse=True)[0][\"index\"])\n",
    "    arm = arms[max_index]\n",
    "    final_reward_type = f\"{arm['name']}_{arm['lamb']}_{seed}\"\n",
    "\n",
    "    final_model_name = f'DQN-stock:{DATASET_NAME}-final_reward:{final_reward_type}-epochs:{n_episodes}-seed:{seed}'\n",
    "\n",
    "    add_train_portfo(train_portfolios, final_model_name, train_portfolio)\n",
    "    add_test_portfo(test_portfolios, final_model_name, test_portfolio)\n",
    "\n",
    "    if show_all:\n",
    "        path = f\"./Results/{DATASET_NAME}/{begin_date}~{end_date}/{seed}/train\"\n",
    "        dirs = os.listdir(path)\n",
    "        for _dir in dirs:\n",
    "            if f\"_{seed}.pkl\" not in _dir: continue\n",
    "            if _dir == f\"model_{seed}.pkl\": continue\n",
    "            \n",
    "            model_dir = f\"{path}/{_dir}\"\n",
    "            agent_eval = agent.test(initial_investment=initial_investment, test_type='train', model_path=model_dir)\n",
    "            train_portfolio = agent_eval.get_daily_portfolio_value()\n",
    "            \n",
    "            agent_test = agent.test(initial_investment=initial_investment, test_type='test', model_path=model_dir)\n",
    "            test_portfolio = agent_test.get_daily_portfolio_value()\n",
    "\n",
    "            reward_type = re.findall(\"model_(.*?).pkl\", _dir)[0]\n",
    "            model_name = f'DQN-stock:{DATASET_NAME}-reward:{reward_type}-epochs:{n_episodes}-seed:{seed}'\n",
    "\n",
    "            add_train_portfo(train_portfolios, model_name, train_portfolio)\n",
    "            add_test_portfo(test_portfolios, model_name, test_portfolio)\n",
    "\n",
    "    # plot_action_point(\n",
    "    #     \"test\", \n",
    "    #     dataTrain_agent, \n",
    "    #     dataTest_agent, \n",
    "    #     data_loader, \n",
    "    #     \"DQN\", \n",
    "    #     DATASET_NAME, \n",
    "    #     begin=0, end=100\n",
    "    # )\n",
    "    \n",
    "    calc_bh(train_portfolios, test_portfolios, data_loader, initial_investment)\n",
    "    indexes = calc_return(data_loader, train_portfolios, test_portfolios)\n",
    "    \n",
    "    flag_biggest = False\n",
    "    flag_top_3 = False\n",
    "    if indexes.T[\"sharpe_train\"][final_model_name] == indexes.T[\"sharpe_train\"].max():\n",
    "        flag_biggest = True\n",
    "    if indexes.T[\"sharpe_train\"][final_model_name] in indexes.T[\"sharpe_train\"].sort_values(ascending=False).values[:3]:\n",
    "        flag_top_3 = True\n",
    "    \n",
    "    path = f\"./Results/{DATASET_NAME}/{begin_date}~{end_date}/{seed}/train_log/\"\n",
    "    logger, handler = setup_logger(f'{DATASET_NAME}-{seed}-final', f'{path}/{seed}.log')\n",
    "    logger.info(f\"symbol: {DATASET_NAME}, seed: {seed}, final reward type: {indexes.T['sharpe_train'][final_model_name]}\")\n",
    "    logger.info(f\"symbol: {DATASET_NAME}, seed: {seed}, top 3: {indexes.T['sharpe_train'].sort_values(ascending=False).values[:3]}\")\n",
    "    logger.info(f\"result: biggest: {flag_biggest}, top 3: {flag_top_3}\")\n",
    "    logger.removeHandler(handler)\n",
    "    return indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portfolios = {}\n",
    "test_portfolios = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = r'AAPL'\n",
    "\n",
    "initial_investment = 1000\n",
    "\n",
    "kwargs = {\n",
    "    \"DATASET_NAME\": DATASET_NAME, \n",
    "    \"begin_date\": '2016-01-01', \n",
    "    \"end_date\": '2019-01-01', \n",
    "    \"split_point\": '2018-01-01', \n",
    "    \"load_from_file\": True, \n",
    "    \"transaction_cost\": 0.0000,\n",
    "    \"initial_investment\": initial_investment,\n",
    "    \"state_mode\": 1,\n",
    "    \"seed\": 42, \n",
    "    \"GAMMA\": 0.7, \n",
    "    \"n_step\": 5, \n",
    "    \"BATCH_SIZE\": 10, \n",
    "    \"ReplayMemorySize\": 20,\n",
    "    \"TARGET_UPDATE\": 5,\n",
    "    \"window_size\": None, \n",
    "    \"train_portfolios\": train_portfolios,\n",
    "    \"test_portfolios\": test_portfolios,\n",
    "    \"lamb\": 0.0,\n",
    "}\n",
    "\n",
    "# NOTE reward_types: profit, sharpe, volatility, regularized\n",
    "# NOTE sharpe: lamb:0.01；volatility: lamb: 10\n",
    "\n",
    "def add_arm(arms, name, lamb):\n",
    "    arm = { \n",
    "        \"index\": len(arms), \n",
    "        \"name\": name, \n",
    "        \"theta\": 0, \n",
    "        \"a\": 1, \n",
    "        \"b\": 1, \n",
    "        \"sharpe_list\": [], \n",
    "        \"cumreturn_list\": [], \n",
    "        \"lamb\": lamb, \n",
    "        \"used\": 0\n",
    "    },\n",
    "    arms.extend(arm)\n",
    "\n",
    "\n",
    "files = os.listdir(\"./Data/\")\n",
    "ls = []\n",
    "for _file in files[:10]:\n",
    "    # NOTE: seed相当于是simulation\n",
    "    for seed in range(100):\n",
    "        \n",
    "        train_portfolios = {}\n",
    "        test_portfolios = {}\n",
    "\n",
    "        arms = []\n",
    "        # add_arm(arms, \"old_profit\", 0)\n",
    "        add_arm(arms, \"future_profit_1\", 0)\n",
    "        # add_arm(arms, \"future_profit_10\", 0)\n",
    "        # add_arm(arms, \"old_sharpe\", 0)\n",
    "\n",
    "        kwargs.update({\n",
    "            \"DATASET_NAME\": _file,\n",
    "            \"reward_type\": \"\",\n",
    "            \"seed\": seed,\n",
    "            \"n_episodes\": 20,\n",
    "            \"arms\": arms,\n",
    "            \"show_all\": True,\n",
    "            \"ratio_threshold\": 3,\n",
    "            \"train_portfolios\": train_portfolios,\n",
    "            \"test_portfolios\": test_portfolios,\n",
    "        })\n",
    "        \n",
    "        indexes = train(**kwargs)\n",
    "        ls.append(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = []\n",
    "for _file in files:\n",
    "    symbol = _file.replace(\".csv\", \"\")\n",
    "    keys = [key for key in test_portfolios.keys() if symbol in key]\n",
    "    \n",
    "    ls = []\n",
    "    ls2 = []\n",
    "    for key in keys:\n",
    "        profit_percentage = pd.DataFrame(test_portfolios[key]).pct_change(1)\n",
    "        total_return = test_portfolios[key][-1] / test_portfolios[key][0] - 1 \n",
    "        if profit_percentage.std()[0] > 0:\n",
    "            sharpe = np.sqrt(252) * profit_percentage.mean()[0] / profit_percentage.std()[0]\n",
    "        else:\n",
    "            sharpe = 0\n",
    "        ls.append(sharpe)\n",
    "        ls2.append(total_return)\n",
    "    if len(ls) == 0: continue\n",
    "    df = pd.read_csv(f\"./Data/{_file}/{_file}.csv\")\n",
    "    df = df.iloc[2013:]\n",
    "    pct = df[\"Close\"].pct_change(1)\n",
    "    bh_return = df[\"Close\"].iloc[-1] / df[\"Close\"].iloc[0] - 1\n",
    "    bh_sharpe = np.sqrt(252) * pct.mean() / pct.std()\n",
    "    a.append(symbol)\n",
    "    print(f\"stock: {symbol}, sharpe: {round(np.median(ls), 4)}, bh_sharpe: {round(bh_sharpe, 4)}, total return: {round(np.median(ls2), 4)}, bh_return: {round(bh_return, 4)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = distinctipy.get_colors(len(train_portfolios.items()))\n",
    "# plot_return(\"train\", DATASET_NAME, data_loader, train_portfolios, test_portfolios, colors, indexes)\n",
    "# plot_return(\"test\", DATASET_NAME, data_loader, train_portfolios, test_portfolios, colors, indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes.loc[(indexes.index != 'mdd_date_train') & (indexes.index != 'mdd_date_test')].mean(axis=1).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "13d8d4cd6f551a18c363f4a9a34e8382caadd65d1d29b8174a12246b9ecfe3e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
